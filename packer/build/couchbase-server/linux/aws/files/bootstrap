#!/bin/bash -e

# This script is called via userdata on the instance by way of the cloud config
# in jenkins and runs at every boot so the ephemeral volumes can be provisioned
# and docker can start up once complete
#
# Any changes made to this script should be made on the understanding that
# it will be triggered on every boot. It touches /.booted at the end
# so if you want to do something only on first boot, check for that file.

set -x
set +e

positional_params=()
while [[ $# -gt 0 ]]; do
  key="$1"

  case $key in
    --parallelism)
      parallelism="$2"
      shift
      shift
      ;;
    --timezone)
      timezone="$2"
      shift
      shift
      ;;
    --ssh-pubkey)
      ssh_pubkey="$2"
      shift
      shift
      ;;
    --test)
      is_test_image=1
      shift
      ;;
    *)
      positional_params+=("$1")
      shift
      ;;
  esac
done

environment="${environment:-${positional_params[0]}}"
service="${service:-${positional_params[1]}}"
timezone="${timezone:-America/Los_Angeles}"

function set_timezone() {
  # Configures timezone, should only run on first boot
  if [ ! -f /.booted ]
  then
    sed -i '/.*ZONE.*/c\ZONE="${timezone}"' /etc/sysconfig/clock
    mv /etc/localtime /etc/localtime.org
    ln -sf /usr/share/zoneinfo/${timezone} /etc/localtime
    echo "${timezone}" > /etc/timezone
  fi
}

function create_var_lib_docker() {
  # If we don't have a (non-root) persistent EBS volume, put /var/lib/docker
  # on the instance store volume
  if [ ! -L /dev/persistent/disk1 ]
  then
    docker_disk="ephemeral"
  else
    docker_disk="persistent"
  fi

  # switcheroo /var/lib/docker if currently unswitcherooed
  if [ ! -d /${docker_disk}/var/lib/docker ]
  then
    rm -rf /var/lib/docker
    mkdir -p /${docker_disk}/var/lib/docker
    ln -s /${docker_disk}/var/lib/docker/ /var/lib/docker
  fi
  mkdir -p /var/lib/docker/cb-home
}

function update_fstab() {
  for disk in ephemeral persistent
  do
    if ! grep ${disk} /etc/fstab
    then
      if [ -L "/dev/${disk}/disk1" ]
      then
        mkdir -p /${disk}
        echo "/dev/${disk}/disk1 /${disk} ext4 defaults,nofail,discard 0 2" >> /etc/fstab
      fi
    fi
  done
}

function get_stackfile() {
  declare -A stackfiles
  stackfiles["analytics"]="analytics/analytics-jenkins-agents.yml"
  stackfiles["cv"]="cv/cv-jenkins-agents.yml"
  stackfiles["server"]="couchbase-server/server-jenkins-agents.yaml"
  stackfiles["sdk"]="sdk/sdk-jenkins-agents.yaml"
  stackfiles["mobile"]="mobile/mobile-jenkins-agents.yaml"
  stackfiles["test"]="couchbase-server/server-jenkins-agents.yaml"

  if [ "${is_test_image}" = "1" ]; then
    branch=aws-testing
  else
    branch=master
  fi
  curl -fLo /opt/buildteam/stackfile.yml "https://raw.githubusercontent.com/couchbase/build-infra/${branch}/docker-stacks/${stackfiles[${environment}]}"
}

function get_disk_type() {
  # Determine disk type by checking the NVMe model string
  # Returns: "ephemeral", "ebs", or "unknown"
  local device=$1
  local nvme_line

  nvme_line=$(nvme list 2>/dev/null | grep "/dev/${device}")

  if echo "${nvme_line}" | grep -q "Instance Storage"; then
    echo "ephemeral"
  elif echo "${nvme_line}" | grep -q "Elastic Block Store"; then
    echo "ebs"
  else
    echo "unknown"
  fi
}

function get_disk_size_gb() {
  # Get disk size in GB (returns integer)
  local device=$1
  local size_bytes

  size_bytes=$(lsblk -b -d -n -o SIZE "/dev/${device}" 2>/dev/null)
  if [ -n "${size_bytes}" ]; then
    echo $((size_bytes / 1024 / 1024 / 1024))
  else
    echo "0"
  fi
}

function provision_disk() {
  local device="${1}n1"

  # Check if device exists
  if ! lsblk -o NAME,FSTYPE -dsn | grep -q "${device}"; then
    echo "Device ${device} not found, skipping"
    return
  fi

  # Determine disk type using positive identification
  local disk_type
  disk_type=$(get_disk_type "${device}")

  # Get disk size for validation and logging
  local size_gb
  size_gb=$(get_disk_size_gb "${device}")

  echo "Examining ${device}: type=${disk_type}, size=${size_gb}GB"

  local name
  if [ "${disk_type}" = "ephemeral" ]; then
    # Require minimum 50GB for ephemeral to avoid accidentally using small disks
    if [ "${size_gb}" -lt 50 ]; then
      echo "WARNING: ${device} identified as Instance Storage but only ${size_gb}GB - skipping (minimum 50GB required)"
      return
    fi
    name=ephemeral
  elif [ "${disk_type}" = "ebs" ]; then
    # Skip small EBS volumes (likely root volume)
    if [ "${size_gb}" -lt 50 ]; then
      echo "Skipping small EBS volume ${device} (${size_gb}GB)"
      return
    fi
    name=persistent
  else
    echo "WARNING: Could not identify disk type for ${device}, skipping"
    echo "nvme list output for debugging:"
    nvme list 2>/dev/null | grep "/dev/${device}" || echo "(no nvme list entry found)"
    return
  fi

  # We need to ensure the ephemeral storage is configured at each boot, we'll
  # skip persistent vol if it already exists though
  if lvs | grep -q "${name}"; then
    echo "LVM volume group '${name}' already exists, skipping ${device}"
    return
  fi

  echo "Provisioning ${device} as ${name} (${size_gb}GB)"

  DISKSIZE_STRING=$(lsblk | grep "${device}" | awk '{print $4}')
  case $DISKSIZE_STRING in
    *G)
      DISK_UNIT=G
      ;;
    *T)
      DISK_UNIT=T
      ;;
  esac
  DISKSIZE_RAW=$(echo $DISKSIZE_STRING | cut -f1 -d$DISK_UNIT)

  if [ $DISK_UNIT = "G" ]
  then
    DISKSIZE_RAW=$(echo "scale=4; $DISKSIZE_RAW-0.1" | bc)
  else
    DISKSIZE_RAW=$(echo "scale=4; $DISKSIZE_RAW-0.001" | bc)
  fi

  pvcreate /dev/${device}
  vgcreate ${name} /dev/${device}
  # lvcreate seems to exit a split second before the disk is ready sometimes,
  # we need to create the filesystem after a short delay to work around this.
  lvcreate --name disk1 --size ${DISKSIZE_RAW}${DISK_UNIT} ${name}
  sleep 2
  mkfs.ext4 /dev/${name}/disk1
  echo "Successfully provisioned ${device} as ${name}"
}

function retrieve_secrets() {
  local environment=${1}
  local target_dir=${2}

  for encoding in none base64
  do
    # Get the names of the secrets we want from parameter store
    secrets=$(aws ssm --region $(</opt/buildteam/region) describe-parameters --parameter-filters "Key=tag:Consumer,Values=jenkins-worker" "Key=tag:Environment,Values=${environment},shared" "Key=tag:Encoding,Values=${encoding}" | jq -r ".Parameters[].Name")

    for secret in ${secrets}
    do
        echo "Reading $secret"
        # We're composing filenames from parameters like: jenkins-worker__server__.ssh__config
        # where each __ is replaced with a / to construct the path.
        #
        # The first two components of the path specify what the parameter's purpose isÂ and the
        # environment it belongs to, with environment always being either ${environment} or
        # 'shared.' We know everything we're reading here belongs to this container though, so
        # we can just strip out the leading jenkins-worker/${environment}/ and use whatever
        # remains as the path.
        #
        # e.g:
        #   jenkins-worker__server__.ssh__config = [/var/lib/docker/cb-home/].ssh/config
        #   jenkins-worker__shared__.ssh__authorized_keys = [/var/lib/docker/cb-home/].ssh/authorized_keys
        secret_path="${target_dir}$(echo ${secret} | sed -e"s/__/\//g;s/^jenkins-worker\/[^\/]*//g")"
        mkdir -p $(dirname $secret_path)
        set +x
        param=$(aws ssm get-parameter --region $(</opt/buildteam/region) --with-decryption --name ${secret} | jq -r ".Parameter.Value")
        case $encoding in
        none)
          echo "${param}" > "${secret_path}"
          ;;
        base64)
          echo "${param}" | base64 --decode > "${secret_path}"
          ;;
        esac
        set -x
    done
  done
}

function build_docker_run_args() {
  # Compile args we'll be passing to `docker run`
  DOCKER_RUN_ARGS=(
    --rm
    --name worker
    --pull always
    -v /etc/timezone:/etc/timezone:ro
    -v /etc/localtime:/etc/localtime:ro
    -v /tmp/aws:/aws
    -v /var/lib/docker/cb-home:/homesecrets
    -v /ephemeral/jenkins:/home/couchbase/jenkins
    -v /ephemeral/tmp:/tmp
    -d
    -p 4000:22
  )

  # CV PARALLELISM env var
  if [ ! -z "${parallelism}" ]
  then
    DOCKER_RUN_ARGS+=( -e "PARALLELISM=${parallelism}" )
  fi

  # CB_ENTRYPOINT_PLUGINS
  if [ ! -z "${entrypoint_plugins}" ]
  then
    DOCKER_RUN_ARGS+=( -e "CB_ENTRYPOINT_PLUGINS=${entrypoint_plugins}" )
  fi
  # CB_ENTRYPOINT_BASE
  if [ ! -z "${entrypoint_base}" ]
  then
    DOCKER_RUN_ARGS+=( -e "CB_ENTRYPOINT_BASE=${entrypoint_base}" )
  fi

  # Mount docker socket
  chown 1000:1000 /var/run/docker.sock
  DOCKER_RUN_ARGS+=( -v /var/run/docker.sock:/var/run/docker.sock )

  # Mount special /opt/couchbase volume for server
  # to enable rpm/deb packaging in sidecar containers
  if [ "${environment}" = "server" ]; then
    DOCKER_RUN_ARGS+=( -v serverbuild_optcouchbase:/opt/couchbase )
  fi

  # Mount CV hook script
  if [ "${environment}" = "cv" ]; then
    DOCKER_RUN_ARGS+=( -v /opt/buildteam/hooks/cv-hook.sh:/usr/sbin/couchhook.d/cv-hook.sh )
  fi

  # Overwrite buildx hook on docker cv workers since the buildx targets in the datacenter
  # won't be available
  if [ "${environment}" = "cv" ] && [ "$(echo "${service}" | grep -c "docker")" -eq 1 ]; then
    rm -rf /tmp/buildx.sh
    echo "#!/bin/bash" > /tmp/buildx.sh
    echo "echo 'Overriding buildx hook - arm workers not available in AWS'" >> /tmp/buildx.sh
    chmod +x /tmp/buildx.sh
    DOCKER_RUN_ARGS+=( -v /tmp/buildx.sh:/usr/sbin/couchhook.d/buildx.sh )
  fi
}

function ecr_login() {
  # Login so we can pull images from ECR
  aws_acct=$(aws sts get-caller-identity | jq -r ".Account")
  aws ecr get-login-password --region $(</opt/buildteam/region) | docker login --username AWS --password-stdin ${aws_acct}.dkr.ecr.$(</opt/buildteam/region).amazonaws.com
}

function container_image() {
  # Determine container image for specified service
  yq e ".services.${service}.image" /opt/buildteam/stackfile.yml
}

function get_env_from_stackfile() {
  local env_key="$1"
  local stackfile="$2"
  local result

  # List format (- KEY=value)
  result=$(yq e -r ".services.${service}.environment[]? | select(test(\"^${env_key}=\")) | sub(\"^${env_key}=\",\"\")" "${stackfile}" 2>/dev/null || true)

  # Map format (KEY: value)
  if [ -z "${result}" ]; then
    result=$(yq e -r ".services.${service}.environment.${env_key} // \"\"" "${stackfile}" 2>/dev/null || true)
  fi

  echo "${result}"
}

function populate_entrypoint_env_from_stackfile() {
  # Populate CB_ENTRYPOINT_* defaults from stackfile for this service, unless
  # explicit flags were provided to this script (flags take precedence).
  local stackfile="/opt/buildteam/stackfile.yml"

  local sf_plugins
  # Use CB_ENTRYPOINT_PLUGINS_EC2 here so that EC2 instances can have
  # different plugins than Docker Swarm-based ones
  sf_plugins=$(get_env_from_stackfile "CB_ENTRYPOINT_PLUGINS_EC2" "${stackfile}")
  if [ -n "${sf_plugins}" ] && [ "${sf_plugins}" != "null" ]
  then
    entrypoint_plugins="${sf_plugins}"
  fi

  local sf_base
  sf_base=$(get_env_from_stackfile "CB_ENTRYPOINT_BASE" "${stackfile}")
  if [ -n "${sf_base}" ] && [ "${sf_base}" != "null" ]
  then
    entrypoint_base="${sf_base}"
  fi
}


# Configure timezone based on --timezone flag (or use America/Los_Angeles if not provided)
set_timezone

# Provision disks...
# NVMe device ordering is non-deterministic and can vary between instance types
# and boots. We scan nvme0 through nvme7 to handle various configurations.
# The provision_disk function uses positive identification (checking for
# "Instance Storage" in the NVMe model string) rather than assuming anything
# that isn't EBS is ephemeral. It also enforces a minimum size of 50GB to
# avoid accidentally using small volumes.
echo "=== Starting disk provisioning ==="
echo "Available NVMe devices:"
nvme list 2>/dev/null || echo "nvme list command failed"
echo ""

for nvme_idx in {0..7}; do
  provision_disk "nvme${nvme_idx}"
done

echo "=== Disk provisioning complete ==="
echo "LVM volumes:"
lvs 2>/dev/null || echo "No LVM volumes found"
echo ""

# More basic disk stuff
update_fstab
mount -a
create_var_lib_docker

set -e
# Start docker in the background so we can move on to retrieving secrets
# straight away
# Note: We don't set the docker service to come up automatically at boot,
# because we need to ensure the disks are ready before the container
# comes up (and we don't set the container to come up automatically because
# we want to ensure we're running from the current image in the stackfile)
service docker start &

# Get secrets from parameter store
retrieve_secrets "host" "/root"
retrieve_secrets "${environment}" "/var/lib/docker/cb-home"
chown -R 1000:1000 /var/lib/docker/cb-home

# If we're passing in an ssh key (for self service), ensure it's present in container's authorized_keys
[ "${ssh_pubkey}" != "" ] \
  && mkdir -p "/var/lib/docker/cb-home/.ssh/" \
  && echo "${ssh_pubkey}" >> /var/lib/docker/cb-home/.ssh/authorized_keys

# wait for docker to finish coming up
while [ ! -f /var/run/docker.pid ]
do
  echo "Waiting for docker to start"
  sleep 1
done

# Authenticate for pulling images from ECR
ecr_login

# Ensure ephemeral /tmp exists and is world-writable
mkdir -p /ephemeral/tmp
chmod 1777 /ephemeral/tmp

# Ensure ephemeral Jenkins dir exists and is owned by 1000:1000
mkdir -p /ephemeral/jenkins
chown 1000:1000 /ephemeral/jenkins

# Run build container
get_stackfile
populate_entrypoint_env_from_stackfile
while ! docker ps --format '{{.Names}}' | grep -w worker &> /dev/null
do
  echo "Attempting to start container..."
  build_docker_run_args
  docker run "${DOCKER_RUN_ARGS[@]}" $(container_image) default
  sleep 5
done

# Allow this script to run at next boot
rm /var/lib/cloud/instances/*/sem/config_scripts_user

touch /.booted
